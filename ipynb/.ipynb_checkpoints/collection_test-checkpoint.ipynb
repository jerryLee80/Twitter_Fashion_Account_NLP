{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Fashion House Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in application keys \n",
    "\n",
    "with open('../data/twitter_keys.txt') as api:\n",
    "    keys = api.read().split('\\n') \n",
    "\n",
    "#Aplication keys\n",
    "\n",
    "import twitter, re, datetime, pandas as pd, numpy as np\n",
    "\n",
    "twitter_keys = {\n",
    "    'consumer_key':        keys[0],\n",
    "    'consumer_secret':     keys[1],\n",
    "    'access_token_key':    keys[2],\n",
    "    'access_token_secret': keys[3]\n",
    "}\n",
    "\n",
    "api = twitter.Api(\n",
    "    consumer_key         =   twitter_keys['consumer_key'],\n",
    "    consumer_secret      =   twitter_keys['consumer_secret'],\n",
    "    access_token_key     =   twitter_keys['access_token_key'],\n",
    "    access_token_secret  =   twitter_keys['access_token_secret'],\n",
    "    tweet_mode           =   'extended'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter API Class\n",
    "\n",
    "class TweetMiner():\n",
    "    \n",
    "    result_limit = 20\n",
    "    api          = None\n",
    "    tweets       = []\n",
    "    \n",
    "    def __init__(self, keys_dict, api, result_limit = 20):\n",
    "        \n",
    "        self.keys_dict     = keys_dict\n",
    "        self.api           = api\n",
    "        self.results_limit = result_limit\n",
    "        \n",
    "    def mine_user_tweets(self, user='gucci', mine_retweets = False, max_pages = None, last_tweet_id = False):\n",
    "        \n",
    "        #time out feedback\n",
    "        print(\"Mining tweets for:\", user)\n",
    "        \n",
    "        tweets        = []\n",
    "        \n",
    "        page           = 1\n",
    "        \n",
    "        while page <= max_pages:\n",
    "            \n",
    "            #time out feedback\n",
    "            print(\"Mining page:\", page)\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses = self.api.GetUserTimeline(\n",
    "                    screen_name = user,\n",
    "                    count       = self.result_limit,\n",
    "                    max_id      = last_tweet_id - 1\n",
    "                )\n",
    "            else:\n",
    "                statuses = self.api.GetUserTimeline(\n",
    "                    screen_name = user,\n",
    "                    count       = self.result_limit\n",
    "                )\n",
    "\n",
    "            for item in statuses:\n",
    "                \n",
    "                last_tweet_id = item.id\n",
    "                \n",
    "                tweets.append({\n",
    "                    'tweet_id': item.id,\n",
    "                    'handle':   item.user.name,\n",
    "                    'text':     item.full_text,\n",
    "                    'created':  item.created_at\n",
    "                })\n",
    "                \n",
    "            page += 1\n",
    "        \n",
    "        return tweets\n",
    "            \n",
    "        \n",
    "miner = TweetMiner(twitter_keys, api, result_limit=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia_labels 95\n",
      "fashion_labels: 45\n",
      "prime_labels: 10\n"
     ]
    }
   ],
   "source": [
    "wikipedia_labels = ['akris_official', 'McQueen', 'alfreddunhill', 'AlphaIndustries', 'andres_sarda', 'Anne_Fontaine',\\\n",
    "                   'aquascutum', 'giorgioarmani', 'emporioarmani', 'ArmaniExchange', 'AspinalofLondon', 'AspreyLondon',\\\n",
    "                   'AleDellAcqua', 'Dior', 'dkny', 'dolcegabbana', '_BadgleyMischka', 'BadgleyMischka', 'BALENCIAGA',\\\n",
    "                   'Bally', 'Balmain', 'BensonAndClegg', 'berluti', 'Beulahlondon', 'ManoloBlahnik', 'HUGOBOSS',\\\n",
    "                    'BottegaVeneta', 'ThomBrowneNY', 'Bulgariofficial', 'Burberry', 'NigelCabourn', 'CalvinKlein',\\\n",
    "                   'camillaandmarc', 'Cartier', 'Dsquared2', 'CERRUTI1881', 'CHANEL', 'Childrensalon', 'chloefashion',\\\n",
    "                   'matthewbridal', 'chromeheartsusa', 'ClementsRibeiro', 'Coach', 'COMMEGARCONS', 'Common Projects',\\\n",
    "                   'corneliajames', 'Corneliani_com', 'CuteCircuit', 'cutlerandgross', 'DegeandSkinner', 'NUMEROVENTUNO',\\\n",
    "                   'dkny', 'dolcegabbana', 'ermannoscervino', 'ESCADA', 'EtroOfficial', 'Faconnable', 'Fendi',\\\n",
    "                    'TOMFORD', 'franksorbier', 'freywilleglobal', 'STUDIO_FULTON', 'DVF', 'JPGaultier', 'GievesLondon',\\\n",
    "                   'givenchy', 'Goyard', 'gucci', 'HackettLondon', 'KevanHallDesign', 'halston', 'Hardy Amies ', 'HELMUTLANG',\\\n",
    "                   'Hermes_Paris', 'HouseofHerrera', 'TommyHilfiger', 'SherriHill', 'GeorgesHobeika', 'marcjacobs', 'jimmychoo',\\\n",
    "                   'johnvarvatos', 'ChristopherKane', 'Karen_Kane', 'katespadeny', 'MaryKatrantzou', ' Khaadi', 'LACOSTE',\\\n",
    "                   'BNYhandbags', 'KarlLagerfeld', 'DerekLamNYC', 'LANVINofficial', 'LardiniOfficial', 'guylaroche', 'Larusmiani',\\\n",
    "                   'JudithLeiber', 'M_Lhuillier', '31philliplim', 'DanLiuTatsuaki', 'Longchamp', 'LouboutinWorld',\\\n",
    "                   'Luxottica', 'BrunoMagli', 'Margiela', 'MarchesaFashion', 'Marimekkoglobal', 'marniofficial',\\\n",
    "                   'maxmara', 'StellaMcCartney', 'MCMtweets', 'MichaelKors', 'Missoni', 'MIUMIUofficial', 'Moschino',\\\n",
    "                   'mouawadjewelry', 'MoynatParis', 'Mugler', 'MulberryEngland', 'charlottes_web', 'RICKOWENSONLINE',\\\n",
    "                   'PauleKa', 'philipp_plein', 'Prada', 'PringleScotland', 'EmilioPucci', 'PacoRabanne', 'Raja Fashions',\\\n",
    "                   'ralphandrusso', 'RalphLauren', 'OscardelaRenta', 'NinaRicci', 'Roberto_Cavalli', 'OfficialRodarte',\\\n",
    "                   'narcisostudio', 'RolandMouret', 'sergiorossi', 'MrRalphRucci', 'soniarykiel', '']\n",
    "\n",
    "\n",
    "fashion_labels = ['gucci', 'McQueen', 'StellaMcCartney', 'Fendi', 'MaisonValentino', 'Roberto_Cavalli',\\\n",
    "                  'LouboutinWorld', 'EtroOfficial', 'Prada', 'dolcegabbana', 'Dior', 'LouisVuitton', 'CHANEL'\\\n",
    "                 'Missoni', 'OscardelaRenta', 'VeraWangGang', 'HerveLeger', 'MaisonValentino', 'Balmain',\\\n",
    "                 'Versace', 'giorgioarmani', 'DerekLamNYC', 'AlbertaFerretti', 'YSL', 'COMMEGARCONS', 'BALENCIAGA',\\\n",
    "                 'Burberry', 'TOMFORD', 'ALEXVAUTHIER', 'MIUMIUofficial', 'CalvinKlein', 'givenchy', 'TommyHilfiger',\\\n",
    "                 'jimmychoo', 'OffWht', 'chloefashion','dkny', 'marcjacobs', 'MichaelKors', 'Goyard', 'HUGOBOSS',\\\n",
    "                 'kenzo', 'HELMUTLANG', 'acnestudios', 'Bulgariofficial', 'akris_official']\n",
    "\n",
    "prime_labels = ['gucci', 'McQueen', 'StellaMcCartney', 'Roberto_Cavalli', 'acnestudios', 'jimmychoo', 'Roberto_Cavalli',\\\n",
    "               'TOMFORD', 'Prada', 'akris_official']\n",
    "\n",
    "print('wikipedia_labels', len(wikipedia_labels))\n",
    "print('fashion_labels:', len(fashion_labels))\n",
    "print('prime_labels:', len(prime_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting and storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraper is not working yet\n",
    "\n",
    "\n",
    "def scrape_label(label):\n",
    "    try:\n",
    "        tweet_data = miner.mine_user_tweets(user=label, max_pages=200, last_tweet_id=True)\n",
    "        df = pd.DataFrame(tweet_data)\n",
    "        df.to_csv('../Tweets/%s.csv' % label)\n",
    "    except:\n",
    "        print('Timed out on:', label)\n",
    "        with open('../Tweets/logfile.txt', 'a+') as f:\n",
    "            f.write(f'Timed out on {label} at {time.ctime()}\\n')\n",
    "        time.sleep(945)\n",
    "        scrape_label(label)\n",
    "        \n",
    "for label in prime_labels:\n",
    "    scrape_label(label)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating class and passing list of twitter handles\n",
    "\n",
    "for label in fashion_labels:\n",
    "    try:\n",
    "        tweet_data = miner.mine_user_tweets(user=label, max_pages=500, last_tweet_id=True)\n",
    "        df = pd.DataFrame(tweet_data)\n",
    "        df.to_csv('../data/%s.csv' % label)\n",
    "    except:\n",
    "        print('could not mine label:', label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113881, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in fashion house csv and creating master datafram\n",
    "\n",
    "acne_df      = pd.read_csv('../data/acnestudios.csv',index_col=[0])\n",
    "akris_df     = pd.read_csv('../data/akris_official.csv',index_col=[0])\n",
    "alberta_df   = pd.read_csv('../data/AlbertaFerretti.csv',index_col=[0])\n",
    "alexvauth_df = pd.read_csv('../data/ALEXVAUTHIER.csv',index_col=[0])\n",
    "balenci_df   = pd.read_csv('../data/BALENCIAGA.csv',index_col=[0])\n",
    "\n",
    "balmain_df   = pd.read_csv('../data/Balmain.csv',index_col=[0])\n",
    "bulgari_df   = pd.read_csv('../data/Bulgariofficial.csv',index_col=[0])\n",
    "burbery_df   = pd.read_csv('../data/Burberry.csv',index_col=[0])\n",
    "calvin_df    = pd.read_csv('../data/CalvinKlein.csv',index_col=[0])\n",
    "chanel_df    = pd.read_csv('../data/CHANEL.csv',index_col=[0])\n",
    "\n",
    "chloe_df     = pd.read_csv('../data/chloefashion.csv',index_col=[0])\n",
    "commes_df    = pd.read_csv('../data/COMMEGARCONS.csv',index_col=[0])\n",
    "dereklam_df  = pd.read_csv('../data/DerekLamNYC.csv',index_col=[0])\n",
    "dior_df      = pd.read_csv('../data/Dior.csv',index_col=[0])\n",
    "dkny_df      = pd.read_csv('../data/dkny.csv',index_col=[0])\n",
    "\n",
    "dolce_df     = pd.read_csv('../data/dolcegabbana.csv',index_col=[0])\n",
    "etro_df      = pd.read_csv('../data/EtroOfficial.csv',index_col=[0])\n",
    "fendi_df     = pd.read_csv('../data/Fendi.csv',index_col=[0])\n",
    "armani_df    = pd.read_csv('../data/giorgioarmani.csv',index_col=[0])\n",
    "givenchy_df  = pd.read_csv('../data/givenchy.csv',index_col=[0])\n",
    "\n",
    "goyard_df    = pd.read_csv('../data/Goyard.csv',index_col=[0])\n",
    "gucci_df     = pd.read_csv('../data/gucci.csv',index_col=[0])\n",
    "helmut_df    = pd.read_csv('../data/HELMUTLANG.csv',index_col=[0])\n",
    "herve_df     = pd.read_csv('../data/HerveLeger.csv',index_col=[0])\n",
    "hugoboss_df  = pd.read_csv('../data/HUGOBOSS.csv',index_col=[0])\n",
    "\n",
    "jimmychoo_df = pd.read_csv('../data/jimmychoo.csv',index_col=[0])\n",
    "lagerfeld_df = pd.read_csv('../data/KarlLagerfeld.csv',index_col=[0])\n",
    "kenzo_df     = pd.read_csv('../data/kenzo.csv',index_col=[0])\n",
    "lanvin_df    = pd.read_csv('../data/LANVINofficial.csv',index_col=[0])\n",
    "Louboutin_df = pd.read_csv('../data/LouboutinWorld.csv',index_col=[0])\n",
    "\n",
    "louisv_df   = pd.read_csv('../data/LouisVuitton.csv',index_col=[0])\n",
    "valentino_df = pd.read_csv('../data/MaisonValentino.csv',index_col=[0])\n",
    "marcjacob_df = pd.read_csv('../data/marcjacobs.csv',index_col=[0])\n",
    "mcqueen_df   = pd.read_csv('../data/McQueen.csv',index_col=[0])\n",
    "kors_df      = pd.read_csv('../data/MichaelKors.csv',index_col=[0])\n",
    "\n",
    "missoni_df   = pd.read_csv('../data/Missoni.csv',index_col=[0])\n",
    "miumiu_df    = pd.read_csv('../data/MIUMIUofficial.csv',index_col=[0])\n",
    "offwht_df    = pd.read_csv('../data/OffWht.csv',index_col=[0])\n",
    "oscar_df     = pd.read_csv('../data/OscardelaRenta.csv',index_col=[0])\n",
    "prada_df     = pd.read_csv('../data/Prada.csv',index_col=[0])\n",
    "\n",
    "cavalli_df   = pd.read_csv('../data/Roberto_Cavalli.csv',index_col=[0])\n",
    "stella_df    = pd.read_csv('../data/StellaMcCartney.csv',index_col=[0])\n",
    "tomford_df   = pd.read_csv('../data/TOMFORD.csv',index_col=[0])\n",
    "hilfiger_df  = pd.read_csv('../data/TommyHilfiger.csv',index_col=[0])\n",
    "verawang_df  = pd.read_csv('../data/VeraWangGang.csv',index_col=[0])\n",
    "\n",
    "versache_df  = pd.read_csv('../data/Versace.csv',index_col=[0])\n",
    "ysl_df       = pd.read_csv('../data/YSL.csv',index_col=[0])\n",
    "\n",
    "\n",
    "df_list = [acne_df, akris_df, alberta_df, alexvauth_df, balenci_df, balmain_df, bulgari_df, burbery_df, calvin_df,\\\n",
    "           chanel_df, chloe_df, commes_df, dereklam_df, dior_df, dkny_df, dolce_df, etro_df, fendi_df,\\\n",
    "           armani_df, givenchy_df, goyard_df, gucci_df, helmut_df, herve_df, hugoboss_df, jimmychoo_df,\\\n",
    "           lagerfeld_df, kenzo_df, lanvin_df, Louboutin_df, louisv_df, valentino_df, marcjacob_df, mcqueen_df,\\\n",
    "           kors_df, missoni_df, miumiu_df, offwht_df, oscar_df, prada_df, cavalli_df, stella_df, tomford_df,\\\n",
    "           hilfiger_df, verawang_df, versache_df, ysl_df]\n",
    "\n",
    "fashion_df = pd.concat(df_list, ignore_index=True)\n",
    "fashion_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "handle\n",
       "Roberto Cavalli        3247\n",
       "Dolce & Gabbana        3245\n",
       "Vera Wang              3244\n",
       "Valentino              3240\n",
       "Stella McCartney       3238\n",
       "Missoni                3238\n",
       "Oscar de la Renta      3234\n",
       "Michael Kors           3234\n",
       "VERSACE                3232\n",
       "HUGO BOSS              3231\n",
       "gucci                  3231\n",
       "Marc Jacobs            3226\n",
       "CALVIN KLEIN           3225\n",
       "Fendi                  3224\n",
       "AlbertaFerretti        3221\n",
       "COMME des GARÇONS      3219\n",
       "ETRO                   3217\n",
       "Burberry               3216\n",
       "Giorgio Armani         3212\n",
       "Alexander McQueen      3209\n",
       "Louis Vuitton          3209\n",
       "Tommy Hilfiger         3205\n",
       "Christian Louboutin    3204\n",
       "Balmain                3204\n",
       "Off-White™             3175\n",
       "Derek Lam              3014\n",
       "Bulgari                2853\n",
       "Chloé                  2813\n",
       "LANVIN                 2704\n",
       "Dior                   2567\n",
       "PRADA                  2005\n",
       "KARL LAGERFELD         1978\n",
       "CHANEL                 1819\n",
       "Herve Leger            1409\n",
       "DKNY                   1278\n",
       "MIU MIU                1228\n",
       "Balenciaga             1203\n",
       "GoyardOfficial         1174\n",
       "Saint Laurent          1045\n",
       "Acne Studios           1000\n",
       "Jimmy Choo             1000\n",
       "TOM FORD               1000\n",
       "Akris                   998\n",
       "GIVENCHY                918\n",
       "Alexandre Vauthier      742\n",
       "KENZO                   332\n",
       "HELMUT LANG             208\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_df.groupby(fashion_df.handle).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_df.to_pickle('../data/fashion_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
